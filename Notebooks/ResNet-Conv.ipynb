{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if using tensorflow2.0+\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Add, Activation, InputLayer, Conv1D, BatchNormalization\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../Data/train.csv')\n",
    "df_train['open_channels'].value_counts(normalize=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_num='all', zeros = True):\n",
    "    #create training data per batch\n",
    "    batch_size = 500000\n",
    "    if batch_num == 'all':\n",
    "        beg = 0\n",
    "        end = 499999999\n",
    "        print('Training on all data')\n",
    "    else:\n",
    "        batch = batch_num\n",
    "        beg = (batch-1)*batch_size \n",
    "        end = batch*batch_size\n",
    "    df_batch = df_train[beg:end]\n",
    "    \n",
    "    # filter out the zero open_channels cases\n",
    "    if not zeros:\n",
    "        df_batch = df_batch.drop(df_batch[df_batch['open_channels']==0].index) #optional, added because model was always predicting 0\n",
    "        \n",
    "    # get data\n",
    "    signal = np.array(df_batch.signal)\n",
    "    open_channels = np.array(df_batch.open_channels).reshape(-1,1)\n",
    "    \n",
    "    # categorize outputs\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit_transform(open_channels)\n",
    "    \n",
    "    # randomize\n",
    "    data = np.zeros((len(signal), 2))\n",
    "    data[:, 0] = signal\n",
    "    data[:, 1] = open_channels.reshape(500000)\n",
    "    data = data.reshape((-1, 1000, 2))\n",
    "    np.random.shuffle(data)\n",
    "    x = data[:,:,0].reshape((-1, 1000,1))\n",
    "    y = data[:,:,1].reshape((-1, 1000,1))\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = .3)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = get_data(5,zeros=True)\n",
    "y_train[60][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(filters=64, size=3, dense=10, dropout=0, depth=1):\n",
    "    #model params\n",
    "    filters = filters\n",
    "    filter_size = size\n",
    "    dropout = dropout\n",
    "    dense_size = dense\n",
    "    \n",
    "    #create model\n",
    "    inputs = Input(shape=(1000,1,))\n",
    "    in_output = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(inputs)\n",
    "\n",
    "    if depth > 0:\n",
    "        k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(in_output)\n",
    "        k = BatchNormalization()(k)\n",
    "        k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(k)\n",
    "        k = Dropout(dropout)(k)\n",
    "        block1 = Add()([k, in_output])\n",
    "        kl = Dense(dense_size, activation='relu')(block1)\n",
    "        \n",
    "        if depth > 1:\n",
    "            k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(block1)\n",
    "            k = BatchNormalization()(k)\n",
    "            k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(k)\n",
    "            k = Dropout(dropout)(k)\n",
    "            block2 = Add()([k, block1])\n",
    "            kl = Dense(dense_size, activation='relu')(block2)\n",
    "\n",
    "            if depth > 2:\n",
    "                k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(block2)\n",
    "                k = BatchNormalization()(k)\n",
    "                k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(k)\n",
    "                k = Dropout(dropout)(k)\n",
    "                block3 = Add()([k, block2])\n",
    "                kl = Dense(dense_size, activation='relu')(block3)\n",
    "\n",
    "                if depth > 3:\n",
    "                    k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(block3)\n",
    "                    k = BatchNormalization()(k)\n",
    "                    k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(k)\n",
    "                    k = Dropout(dropout)(k)\n",
    "                    block4 = Add()([k, block3])\n",
    "                    kl = Dense(dense_size, activation='relu')(block4)\n",
    "                    \n",
    "                    if depth > 4:\n",
    "                        k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(block4)\n",
    "                        k = BatchNormalization()(k)\n",
    "                        k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(k)\n",
    "                        k = Dropout(dropout)(k)\n",
    "                        block5 = Add()([k, block4])\n",
    "                        kl = Dense(dense_size, activation='relu')(block5)\n",
    "                        \n",
    "                        if depth > 5:\n",
    "                            k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(block5)\n",
    "                            k = BatchNormalization()(k)\n",
    "                            k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(k)\n",
    "                            k = Dropout(dropout)(k)\n",
    "                            block6 = Add()([k, block5])\n",
    "                            kl = Dense(dense_size, activation='relu')(block6)\n",
    "                        \n",
    "                            if depth > 6:\n",
    "                                k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(block6)\n",
    "                                k = BatchNormalization()(k)\n",
    "                                k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(k)\n",
    "                                k = Dropout(dropout)(k)\n",
    "                                block7 = Add()([k, block6])\n",
    "                                kl = Dense(dense_size, activation='relu')(block7)\n",
    "                                \n",
    "                                if depth > 7:\n",
    "                                    k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(block7)\n",
    "                                    k = BatchNormalization()(k)\n",
    "                                    k = Conv1D(filters,filter_size,padding='same',activation='relu',strides=1)(k)\n",
    "                                    k = Dropout(dropout)(k)\n",
    "                                    block8 = Add()([k, block7])\n",
    "                                    kl = Dense(dense_size, activation='relu')(block8)\n",
    "\n",
    "    outputs = Dense(units=11, activation='softmax')(kl)\n",
    "    \n",
    "    model = Model(inputs,outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 2s 28ms/sample - loss: 2.7673 - accuracy: 2.0000e-05 - val_loss: 2.4401 - val_accuracy: 0.0014\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 2s 22ms/sample - loss: 2.5032 - accuracy: 1.8286e-04 - val_loss: 2.2755 - val_accuracy: 0.0136\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 2s 22ms/sample - loss: 2.2754 - accuracy: 0.0011 - val_loss: 2.1335 - val_accuracy: 0.0353\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 1s 21ms/sample - loss: 2.0932 - accuracy: 0.0039 - val_loss: 2.0014 - val_accuracy: 0.0698\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 1s 21ms/sample - loss: 1.9321 - accuracy: 0.0585 - val_loss: 1.8772 - val_accuracy: 0.1419\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 2s 22ms/sample - loss: 1.7907 - accuracy: 0.3417 - val_loss: 1.7592 - val_accuracy: 0.8113\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 2s 23ms/sample - loss: 1.6574 - accuracy: 0.6366 - val_loss: 1.6506 - val_accuracy: 0.9712\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 2s 22ms/sample - loss: 1.5329 - accuracy: 0.8381 - val_loss: 1.5481 - val_accuracy: 0.9734\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 2s 22ms/sample - loss: 1.4220 - accuracy: 0.9211 - val_loss: 1.4494 - val_accuracy: 0.9738\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 2s 22ms/sample - loss: 1.3218 - accuracy: 0.9437 - val_loss: 1.3548 - val_accuracy: 0.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e4003d9e48>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = get_data(2,zeros=True)\n",
    "model = resnet(filters=64, dropout=0, depth=1)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test), batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for batch in range(1,11):    \n",
    "    x_train,x_test,y_train,y_test = get_data(batch,zeros=True)\n",
    "    model = resnet(layer_size=256, dropout=0.1, depth=8)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test), batch_size=100, verbose=1)\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    acc.append(score)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = get_data(zeros=True)\n",
    "model = resnet(layer_size=256, dropout=0.1, depth=8)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test), batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2100 samples, validate on 900 samples\n",
      "Epoch 1/10\n",
      "2100/2100 [==============================] - 25s 12ms/sample - loss: 1.8328 - accuracy: 0.4026 - val_loss: 1.5416 - val_accuracy: 0.4345\n",
      "Epoch 2/10\n",
      "2100/2100 [==============================] - 24s 11ms/sample - loss: 1.3786 - accuracy: 0.5270 - val_loss: 1.5093 - val_accuracy: 0.4467\n",
      "Epoch 3/10\n",
      "2100/2100 [==============================] - 25s 12ms/sample - loss: 1.2372 - accuracy: 0.5833 - val_loss: 1.4666 - val_accuracy: 0.4676\n",
      "Epoch 4/10\n",
      "2100/2100 [==============================] - 24s 12ms/sample - loss: 1.1617 - accuracy: 0.6114 - val_loss: 1.4198 - val_accuracy: 0.5007\n",
      "Epoch 5/10\n",
      "2100/2100 [==============================] - 24s 12ms/sample - loss: 1.1056 - accuracy: 0.6255 - val_loss: 1.3203 - val_accuracy: 0.5153\n",
      "Epoch 6/10\n",
      "2100/2100 [==============================] - 26s 12ms/sample - loss: 1.0665 - accuracy: 0.6328 - val_loss: 1.2580 - val_accuracy: 0.5424\n",
      "Epoch 7/10\n",
      "2100/2100 [==============================] - 26s 12ms/sample - loss: 1.0290 - accuracy: 0.6399 - val_loss: 1.1746 - val_accuracy: 0.5622\n",
      "Epoch 8/10\n",
      "2100/2100 [==============================] - 27s 13ms/sample - loss: 1.0022 - accuracy: 0.6443 - val_loss: 1.0650 - val_accuracy: 0.6215\n",
      "Epoch 9/10\n",
      "2100/2100 [==============================] - 26s 13ms/sample - loss: 0.9793 - accuracy: 0.6492 - val_loss: 1.0461 - val_accuracy: 0.6132\n",
      "Epoch 10/10\n",
      "2100/2100 [==============================] - 27s 13ms/sample - loss: 0.9595 - accuracy: 0.6510 - val_loss: 0.9433 - val_accuracy: 0.6528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e408da4898>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model for flat signal type (batches 1-6)\n",
    "x_tr1,x_t1,y_tr1,y_t1 = get_data(1)\n",
    "x_tr2,x_t2,y_tr2,y_t2 = get_data(2)\n",
    "x_tr3,x_t3,y_tr3,y_t3 = get_data(3)\n",
    "x_tr4,x_t4,y_tr4,y_t4 = get_data(4)\n",
    "x_tr5,x_t5,y_tr5,y_t5 = get_data(5)\n",
    "x_tr6,x_t6,y_tr6,y_t6 = get_data(6)\n",
    "x_train = np.concatenate((x_tr1,x_tr2,x_tr3,x_tr4,x_tr5,x_tr6))\n",
    "x_test = np.concatenate((x_t1,x_t2,x_t3,x_t4,x_t5,x_t6))\n",
    "y_train = np.concatenate((y_tr1,y_tr2,y_tr3,y_tr4,y_tr5,y_tr6))\n",
    "y_test = np.concatenate((y_t1,y_t2,y_t3,y_t4,y_t5,y_t6))\n",
    "\n",
    "model1 = resnet(filters=20, size=50, dense=15, dropout=0.1, depth=2)\n",
    "opt = SGD(learning_rate=.005)\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model1.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test), batch_size=80, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('../Models/resconv_flat_85.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1750 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "1750/1750 [==============================] - 37s 21ms/sample - loss: 2.5378 - accuracy: 0.3113 - val_loss: 3.5444 - val_accuracy: 0.2689\n",
      "Epoch 2/10\n",
      "1750/1750 [==============================] - 37s 21ms/sample - loss: 1.8243 - accuracy: 0.4220 - val_loss: 2.5820 - val_accuracy: 0.2979\n",
      "Epoch 3/10\n",
      "1750/1750 [==============================] - 39s 22ms/sample - loss: 1.6835 - accuracy: 0.4344 - val_loss: 2.3148 - val_accuracy: 0.3176\n",
      "Epoch 4/10\n",
      "1750/1750 [==============================] - 39s 22ms/sample - loss: 1.5986 - accuracy: 0.4455 - val_loss: 2.0553 - val_accuracy: 0.3378\n",
      "Epoch 5/10\n",
      "1750/1750 [==============================] - 39s 22ms/sample - loss: 1.5481 - accuracy: 0.4485 - val_loss: 1.9000 - val_accuracy: 0.3617\n",
      "Epoch 6/10\n",
      "1750/1750 [==============================] - 40s 23ms/sample - loss: 1.5111 - accuracy: 0.4521 - val_loss: 1.6636 - val_accuracy: 0.4030\n",
      "Epoch 7/10\n",
      "1750/1750 [==============================] - 40s 23ms/sample - loss: 1.5076 - accuracy: 0.4471 - val_loss: 1.5557 - val_accuracy: 0.4348\n",
      "Epoch 8/10\n",
      "1750/1750 [==============================] - 40s 23ms/sample - loss: 1.4470 - accuracy: 0.4619 - val_loss: 1.5155 - val_accuracy: 0.4370\n",
      "Epoch 9/10\n",
      "1750/1750 [==============================] - 42s 24ms/sample - loss: 1.4405 - accuracy: 0.4625 - val_loss: 1.4513 - val_accuracy: 0.4505\n",
      "Epoch 10/10\n",
      "1750/1750 [==============================] - 41s 23ms/sample - loss: 1.4172 - accuracy: 0.4674 - val_loss: 1.4697 - val_accuracy: 0.4511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e405f8ab70>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model for parabolic signal type (batches 2,7-10)\n",
    "x_tr2,x_t2,y_tr2,y_t2 = get_data(2)\n",
    "x_tr7,x_t7,y_tr7,y_t7 = get_data(7)\n",
    "x_tr8,x_t8,y_tr8,y_t8 = get_data(8)\n",
    "x_tr9,x_t9,y_tr9,y_t9 = get_data(9)\n",
    "x_tr10,x_t10,y_tr10,y_t10 = get_data(10)\n",
    "x_train = np.concatenate((x_tr2,x_tr7,x_tr8,x_tr9,x_tr10))\n",
    "x_test = np.concatenate((x_t2,x_t7,x_t8,x_t9,x_t10))\n",
    "y_train = np.concatenate((y_tr2,y_tr7,y_tr8,y_tr9,y_tr10))\n",
    "y_test = np.concatenate((y_t2,y_t7,y_t8,y_t9,y_t10))\n",
    "\n",
    "model = resnet(filters=10, size=50, dense=25, dropout=0.1, depth=8)\n",
    "opt = SGD(learning_rate = 0.005)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test), batch_size=80, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/resconv_curvy_49.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
